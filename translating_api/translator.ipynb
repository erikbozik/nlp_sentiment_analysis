{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-07T11:14:52.333439Z",
     "start_time": "2024-04-07T11:14:51.728425Z"
    }
   },
   "source": [
    "from hf_hub_ctranslate2 import MultiLingualTranslatorCT2fromHfHub\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T13:42:34.504991Z",
     "start_time": "2024-04-07T13:42:32.655983Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MultiLingualTranslatorCT2fromHfHub(\n",
    "    model_name_or_path=\"michaelfeil/ct2fast-m2m100_1.2B\", device=\"cuda\", compute_type=\"int8_float16\",\n",
    "    tokenizer=AutoTokenizer.from_pretrained(f\"facebook/m2m100_1.2B\")\n",
    ")"
   ],
   "id": "89d6edb87709db8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "500aa656a2ef40869808ad76dd193ab6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/909 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f5c1bf911f647468bd2dc5a2b3b48b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/3.71M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c237c70190949869d2add77ac928b8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m MultiLingualTranslatorCT2fromHfHub(\n\u001B[1;32m      2\u001B[0m     model_name_or_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmichaelfeil/ct2fast-m2m100_1.2B\u001B[39m\u001B[38;5;124m\"\u001B[39m, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, compute_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mint8\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m----> 3\u001B[0m     tokenizer\u001B[38;5;241m=\u001B[39mAutoTokenizer\u001B[38;5;241m.\u001B[39mfrom_pretrained(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfacebook/m2m100_1.2B\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      4\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/models/auto/tokenization_auto.py:858\u001B[0m, in \u001B[0;36mAutoTokenizer.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[0m\n\u001B[1;32m    856\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    857\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m tokenizer_class_py \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 858\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m tokenizer_class_py\u001B[38;5;241m.\u001B[39mfrom_pretrained(pretrained_model_name_or_path, \u001B[38;5;241m*\u001B[39minputs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    859\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    860\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    861\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis tokenizer cannot be instantiated. Please make sure you have `sentencepiece` installed \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    862\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124min order to use this tokenizer.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    863\u001B[0m         )\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:2044\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.from_pretrained\u001B[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001B[0m\n\u001B[1;32m   2042\u001B[0m             resolved_vocab_files[file_id] \u001B[38;5;241m=\u001B[39m download_url(file_path, proxies\u001B[38;5;241m=\u001B[39mproxies)\n\u001B[1;32m   2043\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 2044\u001B[0m         resolved_vocab_files[file_id] \u001B[38;5;241m=\u001B[39m cached_file(\n\u001B[1;32m   2045\u001B[0m             pretrained_model_name_or_path,\n\u001B[1;32m   2046\u001B[0m             file_path,\n\u001B[1;32m   2047\u001B[0m             cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[1;32m   2048\u001B[0m             force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[1;32m   2049\u001B[0m             proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[1;32m   2050\u001B[0m             resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n\u001B[1;32m   2051\u001B[0m             local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m   2052\u001B[0m             token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[1;32m   2053\u001B[0m             user_agent\u001B[38;5;241m=\u001B[39muser_agent,\n\u001B[1;32m   2054\u001B[0m             revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[1;32m   2055\u001B[0m             subfolder\u001B[38;5;241m=\u001B[39msubfolder,\n\u001B[1;32m   2056\u001B[0m             _raise_exceptions_for_gated_repo\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   2057\u001B[0m             _raise_exceptions_for_missing_entries\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   2058\u001B[0m             _raise_exceptions_for_connection_errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m   2059\u001B[0m             _commit_hash\u001B[38;5;241m=\u001B[39mcommit_hash,\n\u001B[1;32m   2060\u001B[0m         )\n\u001B[1;32m   2061\u001B[0m         commit_hash \u001B[38;5;241m=\u001B[39m extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n\u001B[1;32m   2063\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(unresolved_files) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/transformers/utils/hub.py:398\u001B[0m, in \u001B[0;36mcached_file\u001B[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[0m\n\u001B[1;32m    395\u001B[0m user_agent \u001B[38;5;241m=\u001B[39m http_user_agent(user_agent)\n\u001B[1;32m    396\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;66;03m# Load from URL or cache if already cached\u001B[39;00m\n\u001B[0;32m--> 398\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m hf_hub_download(\n\u001B[1;32m    399\u001B[0m         path_or_repo_id,\n\u001B[1;32m    400\u001B[0m         filename,\n\u001B[1;32m    401\u001B[0m         subfolder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(subfolder) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m subfolder,\n\u001B[1;32m    402\u001B[0m         repo_type\u001B[38;5;241m=\u001B[39mrepo_type,\n\u001B[1;32m    403\u001B[0m         revision\u001B[38;5;241m=\u001B[39mrevision,\n\u001B[1;32m    404\u001B[0m         cache_dir\u001B[38;5;241m=\u001B[39mcache_dir,\n\u001B[1;32m    405\u001B[0m         user_agent\u001B[38;5;241m=\u001B[39muser_agent,\n\u001B[1;32m    406\u001B[0m         force_download\u001B[38;5;241m=\u001B[39mforce_download,\n\u001B[1;32m    407\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[1;32m    408\u001B[0m         resume_download\u001B[38;5;241m=\u001B[39mresume_download,\n\u001B[1;32m    409\u001B[0m         token\u001B[38;5;241m=\u001B[39mtoken,\n\u001B[1;32m    410\u001B[0m         local_files_only\u001B[38;5;241m=\u001B[39mlocal_files_only,\n\u001B[1;32m    411\u001B[0m     )\n\u001B[1;32m    412\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m GatedRepoError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    413\u001B[0m     resolved_file \u001B[38;5;241m=\u001B[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:119\u001B[0m, in \u001B[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m check_use_auth_token:\n\u001B[1;32m    117\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m smoothly_deprecate_use_auth_token(fn_name\u001B[38;5;241m=\u001B[39mfn\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, has_token\u001B[38;5;241m=\u001B[39mhas_token, kwargs\u001B[38;5;241m=\u001B[39mkwargs)\n\u001B[0;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fn(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/huggingface_hub/file_download.py:1492\u001B[0m, in \u001B[0;36mhf_hub_download\u001B[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, headers, legacy_cache_layout, endpoint)\u001B[0m\n\u001B[1;32m   1489\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m local_dir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1490\u001B[0m             _check_disk_space(expected_size, local_dir)\n\u001B[0;32m-> 1492\u001B[0m     http_get(\n\u001B[1;32m   1493\u001B[0m         url_to_download,\n\u001B[1;32m   1494\u001B[0m         temp_file,\n\u001B[1;32m   1495\u001B[0m         proxies\u001B[38;5;241m=\u001B[39mproxies,\n\u001B[1;32m   1496\u001B[0m         resume_size\u001B[38;5;241m=\u001B[39mresume_size,\n\u001B[1;32m   1497\u001B[0m         headers\u001B[38;5;241m=\u001B[39mheaders,\n\u001B[1;32m   1498\u001B[0m         expected_size\u001B[38;5;241m=\u001B[39mexpected_size,\n\u001B[1;32m   1499\u001B[0m         displayed_filename\u001B[38;5;241m=\u001B[39mfilename,\n\u001B[1;32m   1500\u001B[0m     )\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m local_dir \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1503\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStoring \u001B[39m\u001B[38;5;132;01m{\u001B[39;00murl\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m in cache at \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mblob_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/huggingface_hub/file_download.py:535\u001B[0m, in \u001B[0;36mhttp_get\u001B[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001B[0m\n\u001B[1;32m    533\u001B[0m new_resume_size \u001B[38;5;241m=\u001B[39m resume_size\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 535\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m r\u001B[38;5;241m.\u001B[39miter_content(chunk_size\u001B[38;5;241m=\u001B[39mDOWNLOAD_CHUNK_SIZE):\n\u001B[1;32m    536\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m chunk:  \u001B[38;5;66;03m# filter out keep-alive new chunks\u001B[39;00m\n\u001B[1;32m    537\u001B[0m             progress\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mlen\u001B[39m(chunk))\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/requests/models.py:816\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    814\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    815\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 816\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    817\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    818\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/response.py:934\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    933\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m--> 934\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(amt\u001B[38;5;241m=\u001B[39mamt, decode_content\u001B[38;5;241m=\u001B[39mdecode_content)\n\u001B[1;32m    936\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m data:\n\u001B[1;32m    937\u001B[0m             \u001B[38;5;28;01myield\u001B[39;00m data\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/response.py:877\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt, decode_content, cache_content)\u001B[0m\n\u001B[1;32m    874\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m amt:\n\u001B[1;32m    875\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer\u001B[38;5;241m.\u001B[39mget(amt)\n\u001B[0;32m--> 877\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raw_read(amt)\n\u001B[1;32m    879\u001B[0m flush_decoder \u001B[38;5;241m=\u001B[39m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data)\n\u001B[1;32m    881\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/response.py:812\u001B[0m, in \u001B[0;36mHTTPResponse._raw_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    809\u001B[0m fp_closed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclosed\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_error_catcher():\n\u001B[0;32m--> 812\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp_read(amt) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m fp_closed \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    813\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m data:\n\u001B[1;32m    814\u001B[0m         \u001B[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001B[39;00m\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;66;03m# Close the connection when no data is returned\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    820\u001B[0m         \u001B[38;5;66;03m# not properly close the connection in all cases. There is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m         \u001B[38;5;66;03m# no harm in redundantly calling close.\u001B[39;00m\n\u001B[1;32m    822\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/site-packages/urllib3/response.py:797\u001B[0m, in \u001B[0;36mHTTPResponse._fp_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    794\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m buffer\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[1;32m    795\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;66;03m# StringIO doesn't like amt=None\u001B[39;00m\n\u001B[0;32m--> 797\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread(amt) \u001B[38;5;28;01mif\u001B[39;00m amt \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/http/client.py:473\u001B[0m, in \u001B[0;36mHTTPResponse.read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m amt \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength:\n\u001B[1;32m    471\u001B[0m     \u001B[38;5;66;03m# clip the read to the \"end of response\"\u001B[39;00m\n\u001B[1;32m    472\u001B[0m     amt \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlength\n\u001B[0;32m--> 473\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfp\u001B[38;5;241m.\u001B[39mread(amt)\n\u001B[1;32m    474\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m s \u001B[38;5;129;01mand\u001B[39;00m amt:\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001B[39;00m\n\u001B[1;32m    476\u001B[0m     \u001B[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001B[39;00m\n\u001B[1;32m    477\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_close_conn()\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/socket.py:706\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    704\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 706\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock\u001B[38;5;241m.\u001B[39mrecv_into(b)\n\u001B[1;32m    707\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    708\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/ssl.py:1314\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1310\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1311\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1312\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1313\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1314\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread(nbytes, buffer)\n\u001B[1;32m   1315\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/anaconda3/envs/nlp/lib/python3.11/ssl.py:1166\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1164\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1166\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m, buffer)\n\u001B[1;32m   1167\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1168\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T13:27:39.758749Z",
     "start_time": "2024-04-07T13:27:38.514621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"Today is a beautiful day and I am assembled my garden grill. It seems that everything is fine. I look forward to making my steak or maybe should I eat something else?\"\n",
    "outputs = model.generate(\n",
    "    [text],\n",
    "    src_lang=[\"en\"],\n",
    "    tgt_lang=[\"sk\"],\n",
    ")\n",
    "print(outputs)"
   ],
   "id": "28a4ed5b50058d2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dnes je krásny deň a ja som zostavený môj záhradný gril. Zdá sa, že všetko je v poriadku. Teším sa na to, aby som si steak alebo možno by som mal jesť niečo iné?']\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:01:06.168400Z",
     "start_time": "2024-04-07T18:01:06.058396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ],
   "id": "a401b65d6d2c47bc",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4708b1017a450705"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:37:25.130780Z",
     "start_time": "2024-04-07T18:37:24.219237Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv(\"Sentiment Analysis Dataset.csv\", on_bad_lines='warn')",
   "id": "2518ece1138f2fe",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26517/2115885436.py:1: ParserWarning: Skipping line 8836: expected 4 fields, saw 5\n",
      "\n",
      "  data = pd.read_csv(\"Sentiment Analysis Dataset.csv\", on_bad_lines='warn')\n",
      "/tmp/ipykernel_26517/2115885436.py:1: ParserWarning: Skipping line 535882: expected 4 fields, saw 7\n",
      "\n",
      "  data = pd.read_csv(\"Sentiment Analysis Dataset.csv\", on_bad_lines='warn')\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:37:27.430971Z",
     "start_time": "2024-04-07T18:37:27.360151Z"
    }
   },
   "cell_type": "code",
   "source": "data = np.array_split(data, 300)",
   "id": "17e0d874e97803b1",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebozik/anaconda3/envs/nlp/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:11:15.594638Z",
     "start_time": "2024-04-07T18:11:15.525476Z"
    }
   },
   "cell_type": "code",
   "source": "len(np.array_split(data, 2))",
   "id": "85ae337db09c713a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ebozik/anaconda3/envs/nlp/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:12:28.301469Z",
     "start_time": "2024-04-07T18:12:28.300151Z"
    }
   },
   "cell_type": "code",
   "source": "del data",
   "id": "a8e31309ef767d67",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T18:12:47.895498Z",
     "start_time": "2024-04-07T18:12:46.945162Z"
    }
   },
   "cell_type": "code",
   "source": "np.array_split(pd.read_csv(\"Sentiment Analysis Dataset.csv\", on_bad_lines='warn'), 10)",
   "id": "cdb7a4ab75465f10",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_26517/1204794247.py:1: ParserWarning: Skipping line 8836: expected 4 fields, saw 5\n",
      "\n",
      "  np.array_split(pd.read_csv(\"Sentiment Analysis Dataset.csv\", on_bad_lines='warn'), 10)\n",
      "/tmp/ipykernel_26517/1204794247.py:1: ParserWarning: Skipping line 535882: expected 4 fields, saw 7\n",
      "\n",
      "  np.array_split(pd.read_csv(\"Sentiment Analysis Dataset.csv\", on_bad_lines='warn'), 10)\n",
      "/home/ebozik/anaconda3/envs/nlp/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[        ItemID  Sentiment SentimentSource  \\\n",
       " 0            1          0    Sentiment140   \n",
       " 1            2          0    Sentiment140   \n",
       " 2            3          1    Sentiment140   \n",
       " 3            4          0    Sentiment140   \n",
       " 4            5          0    Sentiment140   \n",
       " ...        ...        ...             ...   \n",
       " 157857  157870          0    Sentiment140   \n",
       " 157858  157871          1    Sentiment140   \n",
       " 157859  157872          1    Sentiment140   \n",
       " 157860  157873          1    Sentiment140   \n",
       " 157861  157874          0    Sentiment140   \n",
       " \n",
       "                                             SentimentText  \n",
       " 0                            is so sad for my APL frie...  \n",
       " 1                          I missed the New Moon trail...  \n",
       " 2                                 omg its already 7:30 :O  \n",
       " 3                 .. Omgaga. Im sooo  im gunna CRy. I'...  \n",
       " 4                i think mi bf is cheating on me!!!   ...  \n",
       " ...                                                   ...  \n",
       " 157857                     @dELYSEious guilty as charged   \n",
       " 157858  @dELYSEious hahhahahaa. will do. i'll trade ba...  \n",
       " 157859  @dELYSEious I would donate to the Elyse 2k9 To...  \n",
       " 157860  @dELYSEious Only if they are served with holla...  \n",
       " 157861  @dem_lovato_ hey why dont you reply??  was it ...  \n",
       " \n",
       " [157862 rows x 4 columns],\n",
       "         ItemID  Sentiment SentimentSource  \\\n",
       " 157862  157875          1    Sentiment140   \n",
       " 157863  157876          1    Sentiment140   \n",
       " 157864  157877          0    Sentiment140   \n",
       " 157865  157878          1    Sentiment140   \n",
       " 157866  157879          0    Sentiment140   \n",
       " ...        ...        ...             ...   \n",
       " 315719  315732          1    Sentiment140   \n",
       " 315720  315733          0    Sentiment140   \n",
       " 315721  315734          0    Sentiment140   \n",
       " 315722  315735          1    Sentiment140   \n",
       " 315723  315736          0    Sentiment140   \n",
       " \n",
       "                                             SentimentText  \n",
       " 157862  @febrykurniasih im fine babe hhi,long time no ...  \n",
       " 157863                                @fecat1 will do...   \n",
       " 157864  @FeCrisp ur good afternoon never got sent to m...  \n",
       " 157865  @Feddasaur ?? ok i have no idea wtf that came ...  \n",
       " 157866  @feddie138proof yes for me... Just after work ...  \n",
       " ...                                                   ...  \n",
       " 315719       @miss_r I say silver...or purple...or gold.   \n",
       " 315720        @miss_r i've gotta get it sorted out. Crap   \n",
       " 315721  @miss_r Me too     but I'm really intrigued wi...  \n",
       " 315722         @miss_r oh, ok. glad to hear that i guess   \n",
       " 315723  @miss_r: I use twitterfon, which doesn't have ...  \n",
       " \n",
       " [157862 rows x 4 columns],\n",
       "         ItemID  Sentiment SentimentSource  \\\n",
       " 315724  315737          1    Sentiment140   \n",
       " 315725  315738          1    Sentiment140   \n",
       " 315726  315739          1    Sentiment140   \n",
       " 315727  315740          1    Sentiment140   \n",
       " 315728  315741          0    Sentiment140   \n",
       " ...        ...        ...             ...   \n",
       " 473580  473593          1    Sentiment140   \n",
       " 473581  473594          1    Sentiment140   \n",
       " 473582  473595          1    Sentiment140   \n",
       " 473583  473596          1    Sentiment140   \n",
       " 473584  473597          1    Sentiment140   \n",
       " \n",
       "                                             SentimentText  \n",
       " 315724  @miss_r0ss I LOVE THE FACT THAT I RRITATE PEOP...  \n",
       " 315725  @Miss_ReaRea Hey ReaRea...how's it goin? Long ...  \n",
       " 315726       @miss_s_b Sounds great  Can't wait to see it  \n",
       " 315727  @miss_sandrina Hope you have a Very Happy East...  \n",
       " 315728           @Miss_Sez yeah its NOT good  thanks tho!  \n",
       " ...                                                   ...  \n",
       " 473580  @UrbanDecay411 Favourite UD product names: Asp...  \n",
       " 473581                           @urbandecay411 Love it!   \n",
       " 473582  @UrbanDecay411 yes it is  it can be a positive...  \n",
       " 473583  @UrbaneGorilla I'll check out TOPS and FREE--t...  \n",
       " 473584  @UrbaneGorilla sure, but for me is nothing tha...  \n",
       " \n",
       " [157861 rows x 4 columns],\n",
       "         ItemID  Sentiment SentimentSource  \\\n",
       " 473585  473598          0    Sentiment140   \n",
       " 473586  473599          1    Sentiment140   \n",
       " 473587  473600          0    Sentiment140   \n",
       " 473588  473601          1    Sentiment140   \n",
       " 473589  473602          0    Sentiment140   \n",
       " ...        ...        ...             ...   \n",
       " 631441  631457          1    Sentiment140   \n",
       " 631442  631458          0    Sentiment140   \n",
       " 631443  631459          0    Sentiment140   \n",
       " 631444  631460          0    Sentiment140   \n",
       " 631445  631461          1    Sentiment140   \n",
       " \n",
       "                                             SentimentText  \n",
       " 473585  @theadz01 I'm going to see a flat tomorrow, I ...  \n",
       " 473586  @TheAffiliateGuy Good. I shall breathlessly aw...  \n",
       " 473587  @Thealanne ENGLISH JOURNALS SUCK EVEN MORE. TH...  \n",
       " 473588  @thealaskanking @ParamoreInOz laurens round soon   \n",
       " 473589                           @theAlessiaMarie me too   \n",
       " ...                                                   ...  \n",
       " 631441                                        Bed earlyy   \n",
       " 631442  Bed finallly! wish the pain in my leg would go...  \n",
       " 631443           bed for now...studying my saturday away   \n",
       " 631444                     bed i go, back to school 2mro   \n",
       " 631445                      bed is the first step though   \n",
       " \n",
       " [157861 rows x 4 columns],\n",
       "         ItemID  Sentiment SentimentSource  \\\n",
       " 631446  631462          0    Sentiment140   \n",
       " 631447  631463          1    Sentiment140   \n",
       " 631448  631464          1    Sentiment140   \n",
       " 631449  631465          0    Sentiment140   \n",
       " 631450  631466          0    Sentiment140   \n",
       " ...        ...        ...             ...   \n",
       " 789302  789318          0    Sentiment140   \n",
       " 789303  789319          1    Sentiment140   \n",
       " 789304  789320          1    Sentiment140   \n",
       " 789305  789321          1    Sentiment140   \n",
       " 789306  789322          0    Sentiment140   \n",
       " \n",
       "                                             SentimentText  \n",
       " 631446  bed much later than i wanted...up at 5 am for ...  \n",
       " 631447                     Bed now  Good Night Everyone !  \n",
       " 631448  Bed now  still havnt figured out what im doing...  \n",
       " 631449  bed now maybe? idk. I don't have a voice and m...  \n",
       " 631450       Bed now, i'm knackered and school tomorrow!   \n",
       " ...                                                   ...  \n",
       " 789302  had fun tonight, but I don't want to wake up i...  \n",
       " 789303                                  had fun tonight.   \n",
       " 789304  had fun w/ kewtboy this wknd. watched THE HANG...  \n",
       " 789305  Had fun w/the kids last night, dancing and sin...  \n",
       " 789306  Had fun watchin my mom break boards at the par...  \n",
       " \n",
       " [157861 rows x 4 columns],\n",
       "         ItemID  Sentiment SentimentSource  \\\n",
       " 789307  789323          0    Sentiment140   \n",
       " 789308  789324          0    Sentiment140   \n",
       " 789309  789325          1    Sentiment140   \n",
       " 789310  789326          1    Sentiment140   \n",
       " 789311  789327          1    Sentiment140   \n",
       " ...        ...        ...             ...   \n",
       " 947163  947179          0    Sentiment140   \n",
       " 947164  947180          0    Sentiment140   \n",
       " 947165  947181          0    Sentiment140   \n",
       " 947166  947182          0    Sentiment140   \n",
       " 947167  947183          0    Sentiment140   \n",
       " \n",
       "                                             SentimentText  \n",
       " 789307  had fun wit the boyfriend last nite....i'm bou...  \n",
       " 789308     had fun wit the NO boys... now the drive back   \n",
       " 789309  Had fun with @goodpotatoes and @othbot at Drag...  \n",
       " 789310  had fun with @mizzjblog and @TheStyleSpy at Wi...  \n",
       " 789311  Had fun with Colie, then on iChat with Hunt, a...  \n",
       " ...                                                   ...  \n",
       " 947163  I'm still trying to figure out this whole twit...  \n",
       " 947164  i'm still unsure how i can twitter my text mes...  \n",
       " 947165                 I'm still up &amp; I cannot sleep   \n",
       " 947166  I'm still up and it's 4 in the morning. It's m...  \n",
       " 947167  I'm still up and its almost 3am. I have to wak...  \n",
       " \n",
       " [157861 rows x 4 columns],\n",
       "           ItemID  Sentiment SentimentSource  \\\n",
       " 947168    947184          0    Sentiment140   \n",
       " 947169    947185          1    Sentiment140   \n",
       " 947170    947186          1    Sentiment140   \n",
       " 947171    947187          1    Sentiment140   \n",
       " 947172    947188          0    Sentiment140   \n",
       " ...          ...        ...             ...   \n",
       " 1105024  1105040          1    Sentiment140   \n",
       " 1105025  1105041          1    Sentiment140   \n",
       " 1105026  1105042          0    Sentiment140   \n",
       " 1105027  1105043          0    Sentiment140   \n",
       " 1105028  1105044          0    Sentiment140   \n",
       " \n",
       "                                              SentimentText  \n",
       " 947168   i'm still up at 1:00am and i have school tomor...  \n",
       " 947169   im still up dying laughing over the hilarious ...  \n",
       " 947170   I'm still up! Thank you all for praying (: AHA...  \n",
       " 947171   I'm still very happy from last night Drew is a...  \n",
       " 947172   Im still waiting for people to follow me    Me...  \n",
       " ...                                                    ...  \n",
       " 1105024                 @Nessie1234 Hello there. Welcome.   \n",
       " 1105025             @nessiec345 breakfast is on the table   \n",
       " 1105026  @nessiecullen1 I was going to stay chatting wi...  \n",
       " 1105027                  @nessiecullenxD aww. that's sad.   \n",
       " 1105028  @nesslei enjoy! Just checking the raindrops ar...  \n",
       " \n",
       " [157861 rows x 4 columns],\n",
       "           ItemID  Sentiment SentimentSource  \\\n",
       " 1105029  1105045          1    Sentiment140   \n",
       " 1105030  1105046          0    Sentiment140   \n",
       " 1105031  1105047          0    Sentiment140   \n",
       " 1105032  1105048          0    Sentiment140   \n",
       " 1105033  1105049          0    Sentiment140   \n",
       " ...          ...        ...             ...   \n",
       " 1262885  1262901          1    Sentiment140   \n",
       " 1262886  1262902          1    Sentiment140   \n",
       " 1262887  1262903          1    Sentiment140   \n",
       " 1262888  1262904          1    Sentiment140   \n",
       " 1262889  1262905          1    Sentiment140   \n",
       " \n",
       "                                              SentimentText  \n",
       " 1105029  @nessllee I'm not really an X-Men fan (I had P...  \n",
       " 1105030  @NessMia sending positive thoughts. Good luck ...  \n",
       " 1105031  @nesspabz Yes o___0 Gosh, our teacher is killi...  \n",
       " 1105032  @Nessricho hey girl, can you thank Scott for a...  \n",
       " 1105033  @nessssssss im sorry acting a fool. Please for...  \n",
       " ...                                                    ...  \n",
       " 1262885  Wedding gig in Chattanooga: bad. Getting paid ...  \n",
       " 1262886                                  Wedding in a bit   \n",
       " 1262887  Wedding in Jakarta was awesome  Feels great to...  \n",
       " 1262888  Wedding is over. Very sweet. But the bride was...  \n",
       " 1262889  Wedding pictures for Jen and jeremy  it's a be...  \n",
       " \n",
       " [157861 rows x 4 columns],\n",
       "           ItemID  Sentiment SentimentSource  \\\n",
       " 1262890  1262906          1    Sentiment140   \n",
       " 1262891  1262907          1    Sentiment140   \n",
       " 1262892  1262908          1    Sentiment140   \n",
       " 1262893  1262909          0    Sentiment140   \n",
       " 1262894  1262910          0    Sentiment140   \n",
       " ...          ...        ...             ...   \n",
       " 1420746  1420762          1    Sentiment140   \n",
       " 1420747  1420763          1    Sentiment140   \n",
       " 1420748  1420764          0    Sentiment140   \n",
       " 1420749  1420765          1    Sentiment140   \n",
       " 1420750  1420766          0    Sentiment140   \n",
       " \n",
       "                                              SentimentText  \n",
       " 1262890  wedding planning, late into the night... loves...  \n",
       " 1262891                                 Wedding reception   \n",
       " 1262892      Wedding shower, lol. Atleast I got free food   \n",
       " 1262893                     Wedding stress has now begun.   \n",
       " 1262894  Wedding today. 10:45 and time for the first dr...  \n",
       " ...                                                    ...  \n",
       " 1420746                                  has a laptop now   \n",
       " 1420747  Has a lesbian crush on Megan Fox and can't wai...  \n",
       " 1420748  Has a list of things to do today and is so tired   \n",
       " 1420749  has a long list of things to do today. learn v...  \n",
       " 1420750  Has a long week.....and really couldn't be any...  \n",
       " \n",
       " [157861 rows x 4 columns],\n",
       "           ItemID  Sentiment SentimentSource  \\\n",
       " 1420751  1420767          0    Sentiment140   \n",
       " 1420752  1420768          0    Sentiment140   \n",
       " 1420753  1420769          0    Sentiment140   \n",
       " 1420754  1420770          0    Sentiment140   \n",
       " 1420755  1420771          0    Sentiment140   \n",
       " ...          ...        ...             ...   \n",
       " 1578607  1578623          1    Sentiment140   \n",
       " 1578608  1578624          1    Sentiment140   \n",
       " 1578609  1578625          0    Sentiment140   \n",
       " 1578610  1578626          0    Sentiment140   \n",
       " 1578611  1578627          0    Sentiment140   \n",
       " \n",
       "                                              SentimentText  \n",
       " 1420751  has a long weekend with her girlies. But she's...  \n",
       " 1420752                    has a lot of assignments to do   \n",
       " 1420753               has a lot of assignments to work on   \n",
       " 1420754                  has a LOT of her mind right now    \n",
       " 1420755                     has a lot of homework tonight   \n",
       " ...                                                    ...  \n",
       " 1578607               Zzzzzz.... Finally! Night tweeters!   \n",
       " 1578608                        Zzzzzzz, sleep well people   \n",
       " 1578609            ZzzZzZzzzZ... wait no I have homework.   \n",
       " 1578610      ZzZzzzZZZZzzz meh, what am I doing up again?   \n",
       " 1578611                       Zzzzzzzzzzzzzzzzzzz, I wish   \n",
       " \n",
       " [157861 rows x 4 columns]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "32fe547a055f00e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
